/**
 * Elohim Orchestrator Pipeline v2
 *
 * CENTRAL CONTROLLER for all Elohim mono-repo pipelines.
 * This is the ONLY pipeline that receives GitHub webhooks.
 *
 * Key Improvements:
 *   - Explicit deployment tracking with version verification
 *   - Complete changeset analysis (all commits since last build, not just HEAD~1)
 *   - Post-deployment health verification
 *   - Clear decision matrix showing what will be built and why
 *   - Deployment manifest comparing expected vs actual versions
 *
 * Dependency Graph:
 *   elohim-holochain (DNA/hApp, WASM) [cascades: false]
 *       â”œâ”€â”€â–º elohim-edge (builds after DNA when both change, but DNA doesn't auto-trigger Edge)
 *       â”‚                                    â”œâ”€â”€â–º elohim-genesis (seed + test)
 *       â””â”€â”€â–º elohim-steward (manual only)    â”‚
 *   elohim (Angular app) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 */

// =============================================================================
// CONFIGURATION
// =============================================================================

import groovy.transform.Field

@Field def PIPELINES = [
    'elohim-holochain': [
        jenkinsPath: 'holochain/dna/Jenkinsfile',
        changePatterns: ['holochain/dna/', 'holochain/holochain-cache-core/', 'holochain/rna/', 'VERSION'],
        artifacts: ['elohim.happ'],
        dependsOn: [],
        cascades: false,      // Sprint 5: DNA changes don't auto-trigger Edge rebuilds
        triggersGenesis: true,
        deploymentCheck: null  // No deployment, just artifacts
    ],
    'elohim-edge': [
        jenkinsPath: 'holochain/Jenkinsfile',
        changePatterns: ['doorway/', 'doorway-app/', 'holochain/edgenode/', 'holochain/elohim-storage/', 'holochain/crates/', 'VERSION'],
        artifacts: ['elohim-doorway', 'doorway-app', 'elohim-edgenode', 'elohim-storage', 'elohim-happ-installer'],
        dependsOn: ['elohim-holochain'],
        triggersGenesis: true,
        deploymentCheck: [
            dev: 'https://doorway-alpha.elohim.host/health',
            staging: 'https://doorway-staging.elohim.host/health',
            prod: 'https://doorway.elohim.host/health'
        ]
    ],
    'elohim': [
        jenkinsPath: 'Jenkinsfile',
        changePatterns: ['elohim-app/', 'elohim-library/', 'holochain/sdk/', 'VERSION'],
        artifacts: ['elohim-app'],
        dependsOn: [],
        triggersGenesis: true,
        deploymentCheck: [
            dev: 'https://alpha.elohim.host',
            staging: 'https://staging.elohim.host',
            prod: 'https://elohim.host'
        ]
    ],
    'elohim-genesis': [
        jenkinsPath: 'genesis/Jenkinsfile',
        changePatterns: ['genesis/', 'data/'],
        artifacts: [],
        dependsOn: ['elohim-edge', 'elohim'],
        triggersGenesis: false,
        deploymentCheck: null
    ],
    'elohim-steward': [
        jenkinsPath: 'steward/Jenkinsfile',
        changePatterns: ['steward/'],
        artifacts: ['steward-desktop'],
        dependsOn: ['elohim-holochain'],
        manualOnly: true,
        triggersGenesis: false,
        deploymentCheck: null
    ],
    'elohim-sophia': [
        jenkinsPath: 'sophia/Jenkinsfile',
        changePatterns: ['sophia/'],
        artifacts: ['sophia-element'],
        dependsOn: [],
        cascades: true,        // sophia changes should trigger elohim (app) rebuild
        triggersGenesis: false,
        deploymentCheck: null   // Library, not a deployed service
    ]
]

// Environment-specific endpoints for version checking
@Field def VERSION_ENDPOINTS = [
    'doorway-alpha': 'https://doorway-alpha.elohim.host/version',
    'doorway-staging': 'https://doorway-staging.elohim.host/version',
    'doorway-prod': 'https://doorway.elohim.host/version',
    'app-alpha': 'https://alpha.elohim.host/version.json',
    'app-staging': 'https://staging.elohim.host/version.json',
    'app-prod': 'https://elohim.host/version.json'
]

// =============================================================================
// HELPER FUNCTIONS
// =============================================================================

// Derive health endpoints from PIPELINES.deploymentCheck â€” single source of truth
def getHealthEndpoints() {
    def endpoints = [:]
    PIPELINES.each { name, config ->
        config.deploymentCheck?.each { env, url -> endpoints["${name}-${env}"] = url }
    }
    return endpoints
}

def getGitCommitHash() {
    return sh(script: 'git rev-parse --short HEAD', returnStdout: true).trim()
}

// CI Summary helpers for Claude triage
def categorizeFailure(String p) {
    ['elohim-holochain':'DNA_BUILD', 'elohim-edge':'INFRASTRUCTURE',
     'elohim':'APP_BUILD', 'elohim-genesis':'SEEDING', 'elohim-steward':'DESKTOP_BUILD',
     'elohim-sophia':'SOPHIA_BUILD'][p] ?: 'UNKNOWN'
}
def getRemediationHint(String p) {
    ['elohim-holochain':'Check RUSTFLAGS, cargo build locally',
     'elohim-edge':'Check hApp artifact, Harbor creds',
     'elohim':'Run npm run build locally',
     'elohim-genesis':'Check doorway-alpha.elohim.host/health or doorway-staging.elohim.host/health',
     'elohim-steward':'Check Tauri build, hApp artifact',
     'elohim-sophia':'cd sophia && pnpm lint && pnpm test'][p] ?: 'Check logs'
}
def calculateTriagePriority(int f, int u) { f > 0 && u > 0 ? 'CRITICAL' : f > 0 ? 'HIGH' : u > 0 ? 'MEDIUM' : 'LOW' }

/**
 * Advisory P2P peer validation â€” checks doorway /health for P2P status.
 * Logs warnings but never fails the build.
 */
def runP2PValidation(String environment, String doorwayUrl) {
    def result = sh(
        script: """
            set +e
            HEALTH=\$(curl -s --max-time 10 ${doorwayUrl}/health 2>/dev/null)
            if [ \$? -ne 0 ]; then
                echo "P2P [${environment}]: Could not reach ${doorwayUrl}/health"
                exit 0
            fi

            PEERS=\$(echo "\$HEALTH" | python3 -c "import sys,json; d=json.load(sys.stdin); p=d.get('p2p'); print(p.get('connected_peers',0) if p else 'n/a')" 2>/dev/null)
            SYNC_DOCS=\$(echo "\$HEALTH" | python3 -c "import sys,json; d=json.load(sys.stdin); p=d.get('p2p'); print(p.get('sync_documents',0) if p else 'n/a')" 2>/dev/null)
            PEER_ID=\$(echo "\$HEALTH" | python3 -c "import sys,json; d=json.load(sys.stdin); p=d.get('p2p'); print(p.get('peer_id','unknown')[:12] if p else 'n/a')" 2>/dev/null)

            echo "P2P [${environment}]: peers=\${PEERS} sync_docs=\${SYNC_DOCS} peer_id=\${PEER_ID}"

            if [ "\$PEERS" = "n/a" ]; then
                echo "P2P [${environment}]: P2P not enabled on this doorway"
            elif [ "\$PEERS" = "0" ]; then
                echo "P2P [${environment}]: WARNING - no peers connected"
            else
                echo "P2P [${environment}]: OK - \${PEERS} peer(s) connected"
            fi
        """,
        returnStatus: true
    )
    return result == 0
}

def getGitCommitHashFull() {
    return sh(script: 'git rev-parse HEAD', returnStdout: true).trim()
}

/**
 * Analyze all changes since the last orchestrator build.
 *
 * Priority order:
 *   1. FORCE_COMMIT parameter (manual override)
 *   2. Stored global baseline (advances on every completed build, even UNSTABLE)
 *   3. GIT_PREVIOUS_SUCCESSFUL_COMMIT (Jenkins Git plugin - only advances on SUCCESS)
 *   4. HEAD~1 fallback (only diffs the latest push)
 */
def analyzeChangeset(storedGlobalBaseline = null) {
    // 1. Manual override via FORCE_COMMIT parameter
    def baseCommit = params.FORCE_COMMIT?.trim() ?: null

    // 2. Stored global baseline from previous completed build
    if (!baseCommit && storedGlobalBaseline) {
        baseCommit = storedGlobalBaseline
        echo "Using stored global baseline: ${baseCommit.take(8)}"
    }

    // 3. Jenkins Git plugin automatic tracking (only updates on SUCCESS)
    if (!baseCommit) {
        baseCommit = env.GIT_PREVIOUS_SUCCESSFUL_COMMIT
    }

    if (baseCommit) {
        echo "Comparing HEAD against: ${baseCommit}"

        // Verify commit exists (handles force-push/rebase scenarios)
        def commitExists = sh(
            script: "git cat-file -t ${baseCommit} 2>/dev/null || echo 'missing'",
            returnStdout: true
        ).trim()

        if (commitExists == 'commit') {
            return sh(
                script: "git diff --name-only ${baseCommit}..HEAD",
                returnStdout: true
            ).trim().split('\n').findAll { it }
        }

        echo "WARNING: Commit ${baseCommit} not found in repo"
    }

    // 4. Fallback: diff against previous commit only
    // This is conservative - only looks at what changed in the latest push.
    // Once this build succeeds, GIT_PREVIOUS_SUCCESSFUL_COMMIT will be set
    // and future builds will diff correctly.
    echo 'No baseline commit available - diffing HEAD~1 (latest push only)'
    return sh(
        script: 'git diff --name-only HEAD~1 2>/dev/null || git diff --name-only HEAD',
        returnStdout: true
    ).trim().split('\n').findAll { it }
}

/**
 * Determine which pipelines need to run based on changed files.
 * Uses per-pipeline baselines when available to avoid re-triggering
 * pipelines that already built successfully for intermediate changes.
 */
def analyzePipelineRequirements(changedFiles, pipelineBaselines = [:]) {
    // CI config files that shouldn't trigger source builds
    def ciOnlyPatterns = ['orchestrator/', '.claude', '.github/', '.husky/']
    def ciOnlyFiles = ['CLAUDE.md', 'ROADMAP.md']
    def analysis = [:]

    // Cache git diffs per unique baseline commit to avoid redundant calls
    def cachedDiffs = [:]

    PIPELINES.each { name, config ->
        def matchedPatterns = []
        def matchedFiles = []
        def baselineUsed = 'global'

        // Use per-pipeline baseline if available, otherwise fall back to global changeset
        def filesToCheck = changedFiles
        def baseline = pipelineBaselines[name]

        if (baseline) {
            if (!cachedDiffs.containsKey(baseline)) {
                try {
                    def commitExists = sh(
                        script: "git cat-file -t ${baseline} 2>/dev/null || echo 'missing'",
                        returnStdout: true
                    ).trim()
                    if (commitExists == 'commit') {
                        cachedDiffs[baseline] = sh(
                            script: "git diff --name-only ${baseline}..HEAD",
                            returnStdout: true
                        ).trim().split('\n').findAll { it }
                    } else {
                        cachedDiffs[baseline] = null
                    }
                } catch (Exception e) {
                    echo "WARNING: Could not diff from baseline ${baseline.take(8)}: ${e.message}"
                    cachedDiffs[baseline] = null
                }
            }
            if (cachedDiffs[baseline] != null) {
                filesToCheck = cachedDiffs[baseline]
                baselineUsed = baseline.take(8)
            }
        }

        filesToCheck.each { file ->
            // Skip CI-only files (Jenkinsfiles, orchestrator config, hooks, docs)
            if (file.endsWith('Jenkinsfile') ||
                ciOnlyPatterns.any { pattern -> file.startsWith(pattern) } ||
                ciOnlyFiles.contains(file)) {
                return  // skip this file
            }

            config.changePatterns.each { pattern ->
                if (file.startsWith(pattern)) {
                    if (!matchedPatterns.contains(pattern)) {
                        matchedPatterns.add(pattern)
                    }
                    matchedFiles.add(file)
                }
            }
        }

        analysis[name] = [
            shouldRun: !config.manualOnly && matchedPatterns.size() > 0,
            manualOnly: config.manualOnly ?: false,
            matchedPatterns: matchedPatterns,
            matchedFileCount: matchedFiles.size(),
            sampleFiles: matchedFiles.take(5),
            dependsOn: config.dependsOn ?: [],
            triggersGenesis: config.triggersGenesis ?: false,
            baselineUsed: baselineUsed
        ]
    }

    return analysis
}

/**
 * Check deployed version against expected commit
 */
def checkDeployedVersion(String endpoint, String expectedCommit) {
    try {
        def response = sh(
            script: "curl -sf '${endpoint}' 2>/dev/null || echo '{}'",
            returnStdout: true
        ).trim()

        if (response.contains(expectedCommit) || response.contains(expectedCommit.take(7))) {
            return [match: true, response: response]
        }
        return [match: false, response: response, expected: expectedCommit]
    } catch (Exception e) {
        return [match: false, error: e.message]
    }
}

/**
 * Get health status of an endpoint
 */
def checkHealth(String name, String url) {
    def status = sh(
        script: "curl -sf -o /dev/null -w '%{http_code}' '${url}' 2>/dev/null || echo '000'",
        returnStdout: true
    ).trim()
    return [name: name, url: url, status: status, healthy: status in ['200', '301', '302']]
}

/**
 * Order pipelines by dependencies using topological sort
 */
def orderByDependencies(pipelineList) {
    def ordered = []
    def remaining = pipelineList.collect()

    while (!remaining.isEmpty()) {
        def ready = remaining.find { name ->
            def deps = PIPELINES[name].dependsOn ?: []
            deps.every { dep ->
                !remaining.contains(dep) || ordered.contains(dep)
            }
        }

        if (ready) {
            ordered.add(ready)
            remaining.remove(ready)
        } else {
            ordered.addAll(remaining)
            break
        }
    }

    return ordered
}

/**
 * Group pipelines into dependency levels for parallel execution.
 * Pipelines in the same level have no dependencies on each other.
 * Genesis is excluded (always runs last after all builds succeed).
 */
def groupByDependencyLevel(pipelineList) {
    def nonGenesis = pipelineList.findAll { it != 'elohim-genesis' }
    def levels = []
    def placed = [] as Set

    while (placed.size() < nonGenesis.size()) {
        def currentLevel = nonGenesis.findAll { name ->
            if (placed.contains(name)) return false
            def deps = (PIPELINES[name].dependsOn ?: [])
            deps.every { dep -> !nonGenesis.contains(dep) || placed.contains(dep) }
        }
        if (currentLevel.isEmpty()) break
        levels.add(currentLevel)
        placed.addAll(currentLevel)
    }

    return levels
}

/**
 * If a pipeline is building, auto-include all pipelines that depend on it.
 * Uses fixed-point iteration for transitive propagation.
 * Example: DNA builds â†’ edge auto-includes (dependsOn DNA) â†’ genesis auto-includes (dependsOn edge)
 */
def propagateDependencies(pipelines, analysis) {
    def added = true
    while (added) {
        added = false
        PIPELINES.each { name, config ->
            if (pipelines.contains(name)) return          // already building
            if (config.manualOnly) return                  // never auto-trigger

            def deps = config.dependsOn ?: []
            def buildingDep = deps.find { dep ->
                if (!pipelines.contains(dep)) return false
                // Sprint 5: respect cascades flag (default true for backward compat)
                def depConfig = PIPELINES[dep]
                return (depConfig.cascades == null) ? true : depConfig.cascades
            }
            if (buildingDep) {
                pipelines.add(name)
                analysis[name].shouldRun = true
                analysis[name].matchedPatterns.add("dependency:${buildingDep}")
                added = true
            }
        }
    }
    return pipelines
}

/**
 * Load per-pipeline baseline commits from the previous orchestrator build.
 * Each baseline records the commit at which that pipeline last built successfully.
 * This prevents re-triggering pipelines for changes they already built.
 */
def loadPipelineBaselines() {
    def baselines = [:]
    try {
        copyArtifacts(
            projectName: env.JOB_NAME,
            filter: 'pipeline-baselines.json',
            selector: lastCompleted(),
            optional: true,
            flatten: true
        )
        if (fileExists('pipeline-baselines.json')) {
            baselines = readJSON(file: 'pipeline-baselines.json')
            echo "Loaded per-pipeline baselines from previous build"
            baselines.each { name, commit ->
                echo "   ${name}: ${commit.take(8)}"
            }
        } else {
            echo "No previous pipeline baselines found (first run)"
        }
    } catch (Exception e) {
        echo "WARNING: Could not load pipeline baselines: ${e.message}"
        echo "   Using global baseline (GIT_PREVIOUS_SUCCESSFUL_COMMIT)"
    }
    return baselines
}

/**
 * Trigger a pipeline and wait for result
 */
def triggerPipeline(String name, String branch, boolean wait = true) {
    echo "â–¶ï¸ Triggering ${name}/${branch}..."

    try {
        def result = build(
            job: "${name}/${branch}",
            wait: wait,
            propagate: false,
            parameters: [
                booleanParam(name: 'FORCE_BUILD', value: true),
                booleanParam(name: 'FORCE_DEPLOY', value: true)
            ]
        )

        return [
            success: result.result in ['SUCCESS', 'UNSTABLE'],
            unstable: result.result == 'UNSTABLE',
            result: result.result,
            duration: result.duration,
            url: result.absoluteUrl
        ]
    } catch (Exception e) {
        return [
            success: false,
            result: 'ERROR',
            error: e.message
        ]
    }
}

/**
 * Print a decision matrix showing what will be built and why
 */
def printDecisionMatrix(analysis, pipelines) {
    echo '''
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                          DEPLOYMENT DECISION MATRIX                           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£'''

    PIPELINES.each { name, config ->
        def info = analysis[name]
        def willRun = pipelines.contains(name)
        def icon = willRun ? 'ğŸ”¨' : (info.manualOnly ? 'ğŸ”’' : 'â­ï¸')
        def status = willRun ? 'BUILD' : (info.manualOnly ? 'MANUAL' : 'SKIP')

        def reason = info.matchedPatterns.join(', ') ?: 'no changes'
        def baselineInfo = info.baselineUsed && info.baselineUsed != 'global' ? " (since ${info.baselineUsed})" : ''
        echo "â•‘ ${icon} ${name.padRight(20)} â”‚ ${status.padRight(8)} â”‚ ${reason}${baselineInfo}"

        if (info.sampleFiles && info.sampleFiles.size() > 0) {
            info.sampleFiles.each { file ->
                echo "â•‘    â””â”€ ${file}"
            }
        }
    }

    echo '''â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'''
}

/**
 * Print deployment verification results
 */
def printDeploymentVerification(commit, results) {
    echo """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                          DEPLOYMENT VERIFICATION                              â•‘
â•‘  Expected commit: ${commit}
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£"""

    results.each { name, result ->
        def icon = result.match ? 'âœ…' : 'âŒ'
        def status = result.match ? 'VERIFIED' : 'MISMATCH'
        echo "â•‘ ${icon} ${name.padRight(20)} â”‚ ${status}"
        if (!result.match && result.response) {
            echo "â•‘    â””â”€ Got: ${result.response.take(60)}..."
        }
    }

    echo '''â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'''
}

/**
 * Run BDD coverage gap scanner â€” compares conceptual (genesis) vs executable scenarios.
 * Produces an advisory JSON report for quality-architect consumption.
 */
def runBddCoverageGap() {
    dir('orchestrator/e2e') {
        sh 'npm ci'
        sh 'npx tsx scripts/scan-coverage.ts --ci'
    }
}

// =============================================================================
// PIPELINE
// =============================================================================

pipeline {
    agent {
        kubernetes {
            cloud 'kubernetes'
            yaml '''
apiVersion: v1
kind: Pod
spec:
  serviceAccount: jenkins-deployer
  nodeSelector:
    node-type: edge
  containers:
  - name: builder
    image: harbor.ethosengine.com/ethosengine/ci-builder:latest
    command: [cat]
    tty: true
    resources:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        memory: "512Mi"
        cpu: "500m"
'''
        }
    }

    environment {
        // For PR builds, CHANGE_BRANCH holds the source branch (e.g. 'staging');
        // use it so downstream jobs are triggered on the real branch, not 'PR-NNN'.
        BRANCH_NAME = "${env.CHANGE_BRANCH ?: env.BRANCH_NAME ?: 'dev'}"
    }

    parameters {
        choice(
            name: 'MODE',
            choices: ['auto', 'status', 'rebuild-all', 'rebuild-edge', 'rebuild-app', 'genesis-only'],
            description: '''
                auto = Analyze changes and build what's needed (DEFAULT for webhooks)
                status = Report deployment status only (no builds)
                rebuild-all = Force rebuild everything
                rebuild-edge = Force rebuild edge infrastructure (doorway, storage, conductor)
                rebuild-app = Force rebuild Angular app only
                genesis-only = Run seed + test without rebuilding
            '''
        )
        booleanParam(
            name: 'SKIP_GENESIS',
            defaultValue: false,
            description: 'Skip seed+test after builds (useful for infrastructure-only changes)'
        )
        booleanParam(
            name: 'VERIFY_DEPLOYMENT',
            defaultValue: true,
            description: 'Verify deployed versions match built versions after deployment'
        )
        string(
            name: 'FORCE_COMMIT',
            defaultValue: '',
            description: 'Force analysis from a specific commit (leave empty for auto-detect)'
        )
    }

    triggers {
        githubPush()
    }

    options {
        timeout(time: 120, unit: 'MINUTES')
        disableConcurrentBuilds(abortPrevious: true)  // Abort older builds when new one starts
        buildDiscarder(logRotator(numToKeepStr: '100'))
    }

    stages {
        stage('Deduplication Guard') {
            steps {
                script {
                    // Milestone: automatically aborts older builds when a newer one passes this point
                    milestone(ordinal: 1, label: 'Build Started')
                    echo "âœ… Deduplication check passed - proceeding with build #${env.BUILD_NUMBER}"
                }
            }
        }

        stage('Checkout') {
            steps {
                container('builder') {
                    script {
                        sh 'git config --global --add safe.directory "*"'

                        checkout([
                            $class: 'GitSCM',
                            branches: [[name: "*/${env.BRANCH_NAME}"]],
                            extensions: [
                                [$class: 'CloneOption', shallow: false, noTags: true, depth: 50],
                                [$class: 'CleanBeforeCheckout']
                            ],
                            userRemoteConfigs: [[
                                url: 'https://github.com/ethosengine/elohim.git',
                                credentialsId: 'ee-bot-pat'
                            ]]
                        ])

                        env.GIT_COMMIT_SHORT = getGitCommitHash()
                        env.GIT_COMMIT_FULL = getGitCommitHashFull()

                        // Detect build trigger type
                        def buildCause = currentBuild.getBuildCauses()[0]?.shortDescription ?: 'Unknown'
                        def isWebhook = buildCause.contains('GitHub') || buildCause.contains('webhook') || buildCause.contains('SCM')
                        env.BUILD_TRIGGER = isWebhook ? 'WEBHOOK' : 'MANUAL'

                        echo """
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                        ğŸ­ ELOHIM ORCHESTRATOR v2
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Branch:  ${env.BRANCH_NAME}
  Commit:  ${env.GIT_COMMIT_SHORT} (${env.GIT_COMMIT_FULL})
  Mode:    ${params.MODE} ${params.MODE == 'auto' ? '(automatic changeset analysis)' : ''}
  Trigger: ${env.BUILD_TRIGGER} (${buildCause})
  Build:   #${env.BUILD_NUMBER}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                        """

                        // Milestone 2: Abort older builds that reach this point after checkout
                        milestone(ordinal: 2, label: 'Checkout Complete')
                    }
                }
            }
        }

        stage('Pre-flight Health Check') {
            steps {
                container('builder') {
                    script {
                        echo '''
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           PRE-FLIGHT HEALTH CHECK                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜'''

                        def healthResults = [:]
                        getHealthEndpoints().each { name, url ->
                            def result = checkHealth(name, url)
                            healthResults[name] = result
                            echo "${result.healthy ? 'âœ…' : 'âŒ'} ${name}: HTTP ${result.status} - ${url}"
                        }

                        env.PREFLIGHT_HEALTH = writeJSON(returnText: true, json: healthResults)

                        def unhealthy = healthResults.findAll { k, v -> !v.healthy }
                        if (unhealthy.size() > 0) {
                            echo "âš ï¸  WARNING: ${unhealthy.size()} service(s) unhealthy before deployment"
                        }
                    }
                }
            }
        }

        stage('Determine Build Plan') {
            steps {
                container('builder') {
                    script {
                        def mode = params.MODE ?: 'auto'
                        def pipelines = []
                        def analysis = [:]
                        def changedFiles = []

                        echo """
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              BUILD PLAN ANALYSIS                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Mode:    ${mode}
â”‚  Trigger: ${env.BUILD_TRIGGER}
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"""

                        if (mode in ['auto', 'status']) {
                            // Load per-pipeline baselines for accurate change detection
                            def pipelineBaselines = [:]
                            if (!(params.FORCE_COMMIT?.trim())) {
                                pipelineBaselines = loadPipelineBaselines()
                            }

                            // Automatic changeset analysis (uses stored global baseline if available)
                            echo "ğŸ” Analyzing changesets since last build..."
                            changedFiles = analyzeChangeset(pipelineBaselines['__global__'])

                            // Bootstrap safeguard: if no per-pipeline baselines exist and the
                            // changeset is very large, the global baseline is stale (e.g. first
                            // run after adding baselines, or after repeated failures). Fall back
                            // to HEAD~1 to avoid rebuilding the entire history.
                            if (!pipelineBaselines && changedFiles.size() > 50) {
                                echo "âš ï¸ Stale baseline detected (${changedFiles.size()} files, no per-pipeline baselines)"
                                echo "   Falling back to HEAD~1 to avoid unnecessary rebuilds"
                                changedFiles = sh(
                                    script: 'git diff --name-only HEAD~1 2>/dev/null || git diff --name-only HEAD',
                                    returnStdout: true
                                ).trim().split('\n').findAll { it }
                                echo "   Narrowed changeset to ${changedFiles.size()} files"
                            }

                            analysis = analyzePipelineRequirements(changedFiles, pipelineBaselines)
                            env.PIPELINE_BASELINES = writeJSON(returnText: true, json: pipelineBaselines)

                            env.CHANGED_FILES_COUNT = changedFiles.size().toString()
                            env.ANALYSIS_JSON = writeJSON(returnText: true, json: analysis)

                            // Show changed files grouped by area
                            def filesByArea = [:]
                            changedFiles.each { file ->
                                def area = file.split('/')[0]
                                if (!filesByArea[area]) filesByArea[area] = []
                                filesByArea[area].add(file)
                            }

                            echo "ğŸ“ Changed Files (${changedFiles.size()} total):"
                            filesByArea.each { area, files ->
                                echo "   ${area}/ (${files.size()} files)"
                                files.take(3).each { echo "      â””â”€ ${it}" }
                                if (files.size() > 3) echo "      â””â”€ ... and ${files.size() - 3} more"
                            }

                            pipelines = analysis.findAll { name, info -> info.shouldRun }.keySet().toList()

                            // Propagate: if a dependency is building, auto-include its dependents
                            pipelines = propagateDependencies(pipelines, analysis)

                            // Safety net: auto-include genesis if any triggering pipeline builds
                            if (!pipelines.contains('elohim-genesis') && !params.SKIP_GENESIS) {
                                def triggeringPipeline = pipelines.find { PIPELINES[it]?.triggersGenesis }
                                if (triggeringPipeline) {
                                    pipelines.add('elohim-genesis')
                                    analysis['elohim-genesis'].shouldRun = true
                                    analysis['elohim-genesis'].matchedPatterns.add("triggered-by:${triggeringPipeline}")
                                }
                            }

                        } else {
                            // Manual forced builds
                            echo "ğŸ“‹ Using manual build mode: ${mode}"

                            switch (mode) {
                                case 'rebuild-all':
                                    pipelines = ['elohim-holochain', 'elohim-edge', 'elohim']
                                    if (!params.SKIP_GENESIS) pipelines.add('elohim-genesis')
                                    break
                                case 'rebuild-edge':
                                    pipelines = ['elohim-edge']
                                    if (!params.SKIP_GENESIS) pipelines.add('elohim-genesis')
                                    break
                                case 'rebuild-app':
                                    pipelines = ['elohim']
                                    if (!params.SKIP_GENESIS) pipelines.add('elohim-genesis')
                                    break
                                case 'genesis-only':
                                    pipelines = ['elohim-genesis']
                                    break
                            }

                            // Create analysis for display (even for manual mode)
                            PIPELINES.each { name, config ->
                                analysis[name] = [
                                    shouldRun: pipelines.contains(name),
                                    manualOnly: config.manualOnly ?: false,
                                    matchedPatterns: pipelines.contains(name) ? ['manual-mode'] : [],
                                    matchedFileCount: 0,
                                    sampleFiles: [],
                                    dependsOn: config.dependsOn ?: [],
                                    triggersGenesis: config.triggersGenesis ?: false,
                                    baselineUsed: 'global'
                                ]
                            }
                            env.ANALYSIS_JSON = writeJSON(returnText: true, json: analysis)
                        }

                        // Order pipelines by dependencies
                        def ordered = orderByDependencies(pipelines)
                        env.PIPELINES_TO_RUN = ordered.join(',')

                        // ALWAYS show the decision matrix
                        printDecisionMatrix(analysis, ordered)

                        // Set build description
                        if (ordered.isEmpty() && mode == 'auto') {
                            echo 'â„¹ï¸  No pipelines need to run for these changes'
                            currentBuild.description = "No builds needed (${changedFiles.size()} files)"
                        } else if (mode == 'status') {
                            currentBuild.description = "Status check only"
                        } else {
                            currentBuild.description = "${mode}: ${ordered.join(', ')}"
                        }
                    }
                }
            }
        }

        stage('Execute Builds') {
            when {
                expression {
                    params.MODE != 'status' && (env.PIPELINES_TO_RUN ?: '') != ''
                }
            }
            steps {
                container('builder') {
                    script {
                        def pipelines = (env.PIPELINES_TO_RUN ?: '').split(',').findAll { it }
                        def results = [:]
                        def pipelineBaselines = readJSON(text: env.PIPELINE_BASELINES ?: '{}')

                        if (pipelines.isEmpty()) {
                            echo 'â„¹ï¸  No pipelines to execute'
                            return
                        }

                        def levels = groupByDependencyLevel(pipelines)
                        def hasGenesis = pipelines.contains('elohim-genesis')
                        def levelDesc = levels.collect { lvl ->
                            lvl.size() > 1 ? "[${lvl.join(' + ')}]" : lvl[0]
                        }.join(' â†’ ')
                        if (hasGenesis) levelDesc += ' â†’ genesis'

                        echo """
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          EXECUTING BUILDS (PARALLEL)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Plan: ${levelDesc}
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"""

                        // Execute in dependency-level order (parallel within each level)
                        levels.eachWithIndex { level, idx ->
                            echo ''
                            echo 'â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”'
                            echo "ğŸ“¦ Level ${idx}: ${level.join(' + ')}"
                            echo 'â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”'

                            if (level.size() == 1) {
                                def name = level[0]
                                echo "ğŸ”¨ Building: ${name}"
                                def result = triggerPipeline(name, env.BRANCH_NAME, true)
                                results[name] = result
                                if (result.success) {
                                    if (result.unstable) {
                                        echo "âš ï¸ ${name}: UNSTABLE (${result.duration / 1000}s)"
                                    } else {
                                        echo "âœ… ${name}: SUCCESS (${result.duration / 1000}s)"
                                    }
                                    pipelineBaselines[name] = env.GIT_COMMIT_FULL
                                } else {
                                    echo "âŒ ${name}: ${result.result}"
                                    if (result.error) echo "   Error: ${result.error}"
                                }
                            } else {
                                def parallelBuilds = [:]
                                level.each { name ->
                                    parallelBuilds[name] = {
                                        echo "ğŸ”¨ Building: ${name}"
                                        def result = triggerPipeline(name, env.BRANCH_NAME, true)
                                        results[name] = result
                                        if (result.success) {
                                            if (result.unstable) {
                                                echo "âš ï¸ ${name}: UNSTABLE (${result.duration / 1000}s)"
                                            } else {
                                                echo "âœ… ${name}: SUCCESS (${result.duration / 1000}s)"
                                            }
                                            pipelineBaselines[name] = env.GIT_COMMIT_FULL
                                        } else {
                                            echo "âŒ ${name}: ${result.result}"
                                            if (result.error) echo "   Error: ${result.error}"
                                        }
                                    }
                                }
                                parallel parallelBuilds
                            }

                            // Fail fast: abort if any pipeline in this level failed
                            def levelFailed = level.findAll { !results[it]?.success }
                            if (levelFailed) {
                                error "Build(s) failed: ${levelFailed.join(', ')} - Aborting"
                            }
                        }

                        env.BUILD_RESULTS = writeJSON(returnText: true, json: results)
                        env.PIPELINE_BASELINES = writeJSON(returnText: true, json: pipelineBaselines)

                        // Run genesis if requested
                        if (pipelines.contains('elohim-genesis')) {
                            echo ''
                            echo 'â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”'
                            echo 'ğŸŒ± Running Genesis (seed + test)'
                            echo 'â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”'

                            def genesisResult = triggerPipeline('elohim-genesis', env.BRANCH_NAME, true)
                            results['elohim-genesis'] = genesisResult

                            if (genesisResult.success) {
                                echo 'âœ… elohim-genesis: SUCCESS'
                                pipelineBaselines['elohim-genesis'] = env.GIT_COMMIT_FULL
                            } else {
                                echo "âŒ elohim-genesis: ${genesisResult.result}"
                                unstable('Genesis failed - seeding or tests may have issues')
                            }

                            env.BUILD_RESULTS = writeJSON(returnText: true, json: results)
                            env.PIPELINE_BASELINES = writeJSON(returnText: true, json: pipelineBaselines)
                        }
                    }
                }
            }
        }

        stage('Verify Deployment') {
            when {
                expression {
                    params.VERIFY_DEPLOYMENT && params.MODE != 'status' && (env.PIPELINES_TO_RUN ?: '') != ''
                }
            }
            steps {
                container('builder') {
                    script {
                        echo '''
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          POST-DEPLOYMENT VERIFICATION                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜'''

                        // Wait for deployments to stabilize
                        echo 'â³ Waiting 30s for deployments to stabilize...'
                        sleep(30)

                        def verificationResults = [:]

                        VERSION_ENDPOINTS.each { name, url ->
                            def result = checkDeployedVersion(url, env.GIT_COMMIT_SHORT)
                            verificationResults[name] = result
                        }

                        printDeploymentVerification(env.GIT_COMMIT_SHORT, verificationResults)

                        env.VERIFICATION_RESULTS = writeJSON(returnText: true, json: verificationResults)

                        def mismatches = verificationResults.findAll { k, v -> !v.match }
                        if (mismatches.size() > 0) {
                            echo "âš ï¸  WARNING: ${mismatches.size()} deployment(s) may not have the expected version"
                            echo '   This could mean:'
                            echo '   - Deployment is still rolling out'
                            echo '   - Version endpoint not implemented'
                            echo '   - Deployment failed silently'
                        }
                    }
                }
            }
        }

        stage('Post-flight Health Check') {
            steps {
                container('builder') {
                    script {
                        echo '''
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          POST-FLIGHT HEALTH CHECK                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜'''

                        def healthResults = [:]
                        getHealthEndpoints().each { name, url ->
                            def result = checkHealth(name, url)
                            healthResults[name] = result
                            echo "${result.healthy ? 'âœ…' : 'âŒ'} ${name}: HTTP ${result.status}"
                        }

                        env.POSTFLIGHT_HEALTH = writeJSON(returnText: true, json: healthResults)

                        def unhealthy = healthResults.findAll { k, v -> !v.healthy }
                        if (unhealthy.size() > 0) {
                            unstable("${unhealthy.size()} service(s) unhealthy after deployment")
                        }
                    }
                }
            }
        }

        stage('P2P Validation (Advisory)') {
            steps {
                container('builder') {
                    catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
                        script {
                            echo '''
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          P2P PEER VALIDATION (ADVISORY)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜'''
                            def p2pResults = [:]
                            def doorwayEndpoints = [
                                alpha: 'https://doorway-alpha.elohim.host',
                                staging: 'https://doorway-staging.elohim.host',
                            ]
                            doorwayEndpoints.each { env, url ->
                                p2pResults[env] = runP2PValidation(env, url)
                            }
                            currentBuild.description = (currentBuild.description ?: '') +
                                " | P2P: ${p2pResults.collect { k, v -> "${k}=${v ? 'ok' : 'warn'}" }.join(', ')}"
                        }
                    }
                }
            }
        }

        stage('E2E Federation Smoke (Advisory)') {
            when { expression { readJSON(text: env.BUILD_RESULTS ?: '{}').any { it.value?.success } } }
            steps {
                catchError(buildResult: 'UNSTABLE', stageResult: 'UNSTABLE') {
                    container('builder') {
                        script {
                            echo '''
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     E2E FEDERATION SMOKE TEST (ADVISORY)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜'''
                        }
                        dir('orchestrator/e2e') {
                            sh 'npm ci'
                            sh '''
                                E2E_DOORWAY_ALPHA=https://doorway-alpha.elohim.host \
                                E2E_DOORWAY_STAGING=https://doorway-staging.elohim.host \
                                npx cucumber-js --tags "@e2e and @federation"
                            '''
                        }
                    }
                }
            }
            post {
                always {
                    archiveArtifacts artifacts: 'orchestrator/e2e/reports/**', allowEmptyArchive: true
                }
            }
        }

        stage('BDD Coverage Gap (Advisory)') {
            when { expression { readJSON(text: env.BUILD_RESULTS ?: '{}').any { it.value?.success } } }
            steps {
                catchError(buildResult: 'UNSTABLE', stageResult: 'UNSTABLE') {
                    container('builder') {
                        script { runBddCoverageGap() }
                    }
                }
            }
            post {
                always {
                    archiveArtifacts artifacts: 'orchestrator/e2e/reports/coverage-gap-report.json',
                                     allowEmptyArchive: true
                }
            }
        }
    }

    post {
        always {
            container('builder') {
                script {
                    def results = readJSON(text: env.BUILD_RESULTS ?: '{}')
                    def preflight = readJSON(text: env.PREFLIGHT_HEALTH ?: '{}')
                    def postflight = readJSON(text: env.POSTFLIGHT_HEALTH ?: '{}')
                    def verification = readJSON(text: env.VERIFICATION_RESULTS ?: '{}')

                    def successCount = results.count { k, v -> v?.success && !v?.unstable }
                    def unstableCount = results.count { k, v -> v?.unstable }
                    def failCount = results.count { k, v -> !v?.success }
                    def healthyCount = postflight.count { k, v -> v?.healthy }
                    def verifiedCount = verification.count { k, v -> v?.match }

                    echo """
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                              ğŸ“Š ORCHESTRATOR SUMMARY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  Commit:       ${env.GIT_COMMIT_SHORT}
  Branch:       ${env.BRANCH_NAME}
  Mode:         ${params.MODE}

  BUILDS:       âœ… ${successCount} succeeded â”‚ âš ï¸ ${unstableCount} unstable â”‚ âŒ ${failCount} failed
  SERVICES:     ${healthyCount}/${postflight.size()} healthy
  VERIFIED:     ${verifiedCount}/${verification.size()} deployments match commit

${failCount > 0 ? '  âŒ ATTENTION: Build failures detected!' : unstableCount > 0 ? '  âš ï¸  Some builds unstable (quality gate warnings)' : '  âœ… All builds completed successfully'}
${healthyCount < postflight.size() ? '  âš ï¸  ATTENTION: Some services unhealthy!' : ''}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    """

                    if (failCount > 0) {
                        echo 'Failed pipelines:'
                        results.findAll { k, v -> !v?.success }.each { name, result ->
                            echo "  âŒ ${name}: ${result?.result ?: 'UNKNOWN'}"
                            if (result?.url) echo "     ${result.url}"
                    }
                }

                    if (unstableCount > 0) {
                        echo 'Unstable pipelines:'
                        results.findAll { k, v -> v?.unstable }.each { name, result ->
                            echo "  âš ï¸ ${name}: UNSTABLE"
                            if (result?.url) echo "     ${result.url}"
                        }
                    }

                    // Propagate unstable status to orchestrator build
                    if (failCount == 0 && unstableCount > 0) {
                        currentBuild.result = 'UNSTABLE'
                    }

                    // Generate machine-readable CI summary for Claude consumption
                    def unhealthyCount = postflight.count { k, v -> !v?.healthy }
                    def ciSummary = [
                        schema_version: '1.0.0',
                        timestamp: new Date().format("yyyy-MM-dd'T'HH:mm:ss'Z'", TimeZone.getTimeZone('UTC')),
                        orchestration: [
                            build_number: env.BUILD_NUMBER,
                            build_url: env.BUILD_URL,
                            branch: env.BRANCH_NAME,
                            commit: env.GIT_COMMIT_SHORT ?: 'unknown',
                            mode: params.MODE,
                            duration_seconds: (System.currentTimeMillis() - currentBuild.startTimeInMillis) / 1000
                        ],
                        pipelines: results.collect { name, r ->
                            [
                                name: name,
                                status: r?.unstable ? 'UNSTABLE' : (r?.success ? 'SUCCESS' : (r?.result ?: 'FAILURE')),
                                url: r?.url,
                                duration_ms: r?.duration,
                                category: r?.success ? null : categorizeFailure(name),
                                remediation_hint: r?.success ? null : getRemediationHint(name)
                            ]
                        },
                        health: [
                            preflight: preflight,
                            postflight: postflight,
                            degraded_services: postflight.findAll { k, v -> !v?.healthy }.keySet().toList()
                        ],
                        deployment: [
                            verified: verification.every { k, v -> v?.match },
                            verification_results: verification,
                            mismatches: verification.findAll { k, v -> !v?.match }.keySet().toList()
                        ],
                        summary: [
                            overall_status: failCount > 0 ? 'FAILURE' : (unstableCount > 0 || unhealthyCount > 0 ? 'UNSTABLE' : 'SUCCESS'),
                            builds_succeeded: successCount,
                            builds_unstable: unstableCount,
                            builds_failed: failCount,
                            services_healthy: healthyCount,
                            services_total: postflight.size(),
                            failed_pipelines: results.findAll { k, v -> !v?.success }.keySet().toList(),
                            triage_priority: calculateTriagePriority(failCount, unhealthyCount),
                            action_required: failCount > 0 ? results.findAll { k, v -> !v?.success }.collect { name, r ->
                                "${name}: ${getRemediationHint(name)}"
                            } : []
                        ]
                    ]

                    writeJSON file: 'ci-summary.json', json: ciSummary, pretty: 2

                    // Archive per-pipeline baselines for next run's change detection
                    // __global__ advances on every completed build (even UNSTABLE),
                    // preventing stale GIT_PREVIOUS_SUCCESSFUL_COMMIT from re-triggering everything
                    def pipelineBaselines = readJSON(text: env.PIPELINE_BASELINES ?: '{}')
                    if (env.GIT_COMMIT_FULL) {
                        pipelineBaselines['__global__'] = env.GIT_COMMIT_FULL
                    }
                    writeJSON file: 'pipeline-baselines.json', json: pipelineBaselines, pretty: 2

                    archiveArtifacts artifacts: 'ci-summary.json,pipeline-baselines.json', allowEmptyArchive: true
                    echo "ğŸ“‹ CI Summary archived: ${env.BUILD_URL}artifact/ci-summary.json"
                }
            }
        }
    }
}
